{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96381e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moid\\Downloads\\Assignment 3\\nutrition-plp\\plp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings # <- FREE EMBEDDINGS\n",
    "from langchain_community.chat_models import ChatOllama         # <- FREE LLM\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed7c1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Documents\n",
    "corpus_dir = './corpus/'\n",
    "documents = []\n",
    "for file_name in os.listdir(corpus_dir):\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(corpus_dir, file_name)\n",
    "        loader = PyMuPDFLoader(file_path)\n",
    "        documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5569d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split Documents into Chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ba0ef72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moid\\AppData\\Local\\Temp\\ipykernel_8056\\4036291978.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n"
     ]
    }
   ],
   "source": [
    "# 3. Create FREE Embeddings and Store in ChromaDB\n",
    "# This uses a model from Hugging Face that runs on your machine.\n",
    "# The model will be downloaded automatically the first time you run this.\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703ad05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moid\\AppData\\Local\\Temp\\ipykernel_8056\\2921444647.py:8: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "# Create the vector store\n",
    "persist_directory = 'db' # Use a new directory for the new embeddings\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdbc32f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moid\\AppData\\Local\\Temp\\ipykernel_8056\\3264212117.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3\")\n",
      "C:\\Users\\Moid\\AppData\\Local\\Temp\\ipykernel_8056\\3264212117.py:6: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "# 4. Build the RAG Chain with a FREE LLM\n",
    "# Initialize the free Llama 3 model running via Ollama\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "# Load the vector store and create the retriever\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Create the prompt template\n",
    "system_prompt = (\n",
    "    \"You are a knowledgeable and precise fitness and nutrition science assistant. \"\n",
    "    \"Answer the user's question based only on the context provided. \"\n",
    "    \"If the context doesn't contain the answer, state that you cannot answer from the provided documents. \"\n",
    "    \"Always include a disclaimer that you are not a medical doctor and this is for educational purposes.\\n\\n\"\n",
    "    \"context : \\n {context}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "995ff040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run the RAG chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e9c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Answer:\n",
      "I'm not a medical doctor, but I can provide you with information based on the provided context.\n",
      "\n",
      "According to the text, while a ketogenic diet has been shown to provide short-term benefits in some people, including weight loss and improvements in total cholesterol, blood sugar, and blood pressure, the evidence is limited due to small sample sizes, short durations (12 weeks or less), and lack of control groups. Additionally, long-term effects (beyond one year) are not significantly different from conventional weight loss diets.\n",
      "\n",
      "It's also important to note that eliminating several food groups and potential unpleasant symptoms may make compliance difficult. Furthermore, an emphasis on foods high in saturated fat counters recommendations from the Dietary Guidelines for Americans and the American Heart Association, which may have adverse effects on blood LDL cholesterol.\n",
      "\n",
      "The provided context also mentions a study comparing low-fat diets with very-low-carbohydrate ketogenic diets in obese participants for 1-2 years. The study found that the ketogenic diet produced a small but significantly greater reduction in weight, triglycerides, and blood pressure, as well as a greater increase in HDL and LDL cholesterol compared to the low-fat diet at one year.\n",
      "\n",
      "In conclusion, while a ketogenic diet may have some benefits, it's essential to consult with a healthcare professional and a registered dietitian to closely monitor any biochemical changes and create a personalized meal plan that suits your individual needs and health conditions.\n",
      "\n",
      "## Sources Used:\n",
      "- ./corpus/source 3 - Harvard Diet Reviews.pdf, page 71\n",
      "- ./corpus/source 3 - Harvard Diet Reviews.pdf, page 70\n",
      "- ./corpus/source 3 - Harvard Diet Reviews.pdf, page 66\n",
      "- ./corpus/source 3 - Harvard Diet Reviews.pdf, page 64\n"
     ]
    }
   ],
   "source": [
    "# --- Test it! ---\n",
    "question = \"Okay, I am just getting \"\n",
    "response = rag_chain.invoke({\"input\": question})\n",
    "\n",
    "print(\"## Answer:\")\n",
    "print(response[\"answer\"])\n",
    "print(\"\\n## Sources Used:\")\n",
    "for doc in response[\"context\"]:\n",
    "    print(f\"- {doc.metadata.get('source', 'Unknown source')}, page {doc.metadata.get('page', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d76e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Personal Learning Portal is ready!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747f29b83cc3424bab540baa0bc4b834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Question:', layout=Layout(height='100px', width='90%'), placeholder='Ask a queâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55c28495f0e423ea644061e6736d7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Get Answer', icon='question', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfeb6eaefb5346b39ddbcdc2e6ebcc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- All your previous setup code goes here ---\n",
    "# (Imports, loading documents, splitting, creating the RAG chain, etc.)\n",
    "# Make sure your 'rag_chain' variable is created before this block.\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# 1. Define the UI Widgets\n",
    "# A text area for the user to type their question\n",
    "question_input = widgets.Textarea(\n",
    "    placeholder='Ask a question about weight loss...',\n",
    "    description='Question:',\n",
    "    layout={'width': '90%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "# A button to submit the question\n",
    "submit_button = widgets.Button(\n",
    "    description='Get Answer',\n",
    "    button_style='success',\n",
    "    icon='question'\n",
    ")\n",
    "\n",
    "# An output area to display the results\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# 2. Create a function to handle the button click\n",
    "def on_button_clicked(b):\n",
    "    # This function runs when the button is pressed\n",
    "    with output_area:\n",
    "        output_area.clear_output() # Clear previous results\n",
    "        question = question_input.value\n",
    "        if not question:\n",
    "            print(\"Please enter a question.\")\n",
    "            return\n",
    "        \n",
    "        print(\"Thinking...\")\n",
    "        \n",
    "        # --- Run your RAG Chain ---\n",
    "        response = rag_chain.invoke({\"input\": question})\n",
    "        \n",
    "        # Format the output for better readability\n",
    "        answer = response[\"answer\"]\n",
    "        sources = response[\"context\"]\n",
    "        \n",
    "        # Clear the \"Thinking...\" message and display the final result\n",
    "        output_area.clear_output()\n",
    "        \n",
    "        # Display the answer\n",
    "        display(HTML(f\"<h3>Answer:</h3><p>{answer}</p>\"))\n",
    "        \n",
    "        # Display the sources\n",
    "        sources_html = \"<h3>Sources Used:</h3><ul>\"\n",
    "        for doc in sources:\n",
    "            source_file = doc.metadata.get('source', 'Unknown source')\n",
    "            page_num = doc.metadata.get('page', 'N/A')\n",
    "            sources_html += f\"<li>{source_file}, page {page_num}</li>\"\n",
    "        sources_html += \"</ul>\"\n",
    "        display(HTML(sources_html))\n",
    "\n",
    "# 3. Link the button to the function\n",
    "submit_button.on_click(on_button_clicked)\n",
    "\n",
    "# 4. Display the interactive elements\n",
    "# This will render the UI in your notebook cell\n",
    "print(\"Your Personal Learning Portal is ready!\")\n",
    "display(question_input, submit_button, output_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e0b013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
